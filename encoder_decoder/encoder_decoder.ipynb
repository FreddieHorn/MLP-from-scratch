{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the MLP with one hidden layer\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.hidden(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        max_value = torch.max(x)\n",
    "        max_indices = (x == max_value)\n",
    "        y = torch.zeros_like(x)\n",
    "        y[max_indices] = 1\n",
    "        return y\n",
    "\n",
    "# Define the training function\n",
    "def train(model, inputs, targets, num_epochs, learning_rate):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100000, Loss: 0.21633683145046234\n",
      "Epoch 200/100000, Loss: 0.18385452032089233\n",
      "Epoch 300/100000, Loss: 0.15945392847061157\n",
      "Epoch 400/100000, Loss: 0.14146891236305237\n",
      "Epoch 500/100000, Loss: 0.12886402010917664\n",
      "Epoch 600/100000, Loss: 0.1205984354019165\n",
      "Epoch 700/100000, Loss: 0.11541137099266052\n",
      "Epoch 800/100000, Loss: 0.11220740526914597\n",
      "Epoch 900/100000, Loss: 0.11020274460315704\n",
      "Epoch 1000/100000, Loss: 0.10890164971351624\n",
      "Epoch 1100/100000, Loss: 0.10801559686660767\n",
      "Epoch 1200/100000, Loss: 0.10737068951129913\n",
      "Epoch 1300/100000, Loss: 0.10686685889959335\n",
      "Epoch 1400/100000, Loss: 0.10644428431987762\n",
      "Epoch 1500/100000, Loss: 0.10606785863637924\n",
      "Epoch 1600/100000, Loss: 0.10571304708719254\n",
      "Epoch 1700/100000, Loss: 0.10535840690135956\n",
      "Epoch 1800/100000, Loss: 0.10495274513959885\n",
      "Epoch 1900/100000, Loss: 0.10454490780830383\n",
      "Epoch 2000/100000, Loss: 0.10412853956222534\n",
      "Epoch 2100/100000, Loss: 0.1037018820643425\n",
      "Epoch 2200/100000, Loss: 0.10327055305242538\n",
      "Epoch 2300/100000, Loss: 0.1028231754899025\n",
      "Epoch 2400/100000, Loss: 0.10235787183046341\n",
      "Epoch 2500/100000, Loss: 0.10187263786792755\n",
      "Epoch 2600/100000, Loss: 0.10136605054140091\n",
      "Epoch 2700/100000, Loss: 0.1008363738656044\n",
      "Epoch 2800/100000, Loss: 0.10028372704982758\n",
      "Epoch 2900/100000, Loss: 0.09970875084400177\n",
      "Epoch 3000/100000, Loss: 0.09910967200994492\n",
      "Epoch 3100/100000, Loss: 0.09848837554454803\n",
      "Epoch 3200/100000, Loss: 0.09784369170665741\n",
      "Epoch 3300/100000, Loss: 0.097178153693676\n",
      "Epoch 3400/100000, Loss: 0.09649433940649033\n",
      "Epoch 3500/100000, Loss: 0.09579160809516907\n",
      "Epoch 3600/100000, Loss: 0.09507038444280624\n",
      "Epoch 3700/100000, Loss: 0.09433302283287048\n",
      "Epoch 3800/100000, Loss: 0.09357821196317673\n",
      "Epoch 3900/100000, Loss: 0.09280696511268616\n",
      "Epoch 4000/100000, Loss: 0.09201991558074951\n",
      "Epoch 4100/100000, Loss: 0.09121528267860413\n",
      "Epoch 4200/100000, Loss: 0.09039414674043655\n",
      "Epoch 4300/100000, Loss: 0.0895548164844513\n",
      "Epoch 4400/100000, Loss: 0.08869592100381851\n",
      "Epoch 4500/100000, Loss: 0.08782516419887543\n",
      "Epoch 4600/100000, Loss: 0.0869341716170311\n",
      "Epoch 4700/100000, Loss: 0.08602319657802582\n",
      "Epoch 4800/100000, Loss: 0.08509139716625214\n",
      "Epoch 4900/100000, Loss: 0.08413691073656082\n",
      "Epoch 5000/100000, Loss: 0.08316127210855484\n",
      "Epoch 5100/100000, Loss: 0.0821656733751297\n",
      "Epoch 5200/100000, Loss: 0.08107106387615204\n",
      "Epoch 5300/100000, Loss: 0.07998120784759521\n",
      "Epoch 5400/100000, Loss: 0.07891068607568741\n",
      "Epoch 5500/100000, Loss: 0.07771679013967514\n",
      "Epoch 5600/100000, Loss: 0.07648781687021255\n",
      "Epoch 5700/100000, Loss: 0.07532588392496109\n",
      "Epoch 5800/100000, Loss: 0.07427378743886948\n",
      "Epoch 5900/100000, Loss: 0.07327241450548172\n",
      "Epoch 6000/100000, Loss: 0.07230723649263382\n",
      "Epoch 6100/100000, Loss: 0.07137962430715561\n",
      "Epoch 6200/100000, Loss: 0.07048652321100235\n",
      "Epoch 6300/100000, Loss: 0.06962708383798599\n",
      "Epoch 6400/100000, Loss: 0.0687987431883812\n",
      "Epoch 6500/100000, Loss: 0.06799937784671783\n",
      "Epoch 6600/100000, Loss: 0.06722811609506607\n",
      "Epoch 6700/100000, Loss: 0.0664830356836319\n",
      "Epoch 6800/100000, Loss: 0.06576203554868698\n",
      "Epoch 6900/100000, Loss: 0.0650639533996582\n",
      "Epoch 7000/100000, Loss: 0.06438691169023514\n",
      "Epoch 7100/100000, Loss: 0.06373009830713272\n",
      "Epoch 7200/100000, Loss: 0.06309205293655396\n",
      "Epoch 7300/100000, Loss: 0.06247192621231079\n",
      "Epoch 7400/100000, Loss: 0.06186806410551071\n",
      "Epoch 7500/100000, Loss: 0.061279166489839554\n",
      "Epoch 7600/100000, Loss: 0.060703735798597336\n",
      "Epoch 7700/100000, Loss: 0.06014113128185272\n",
      "Epoch 7800/100000, Loss: 0.05958976224064827\n",
      "Epoch 7900/100000, Loss: 0.059049155563116074\n",
      "Epoch 8000/100000, Loss: 0.058518074452877045\n",
      "Epoch 8100/100000, Loss: 0.05799569562077522\n",
      "Epoch 8200/100000, Loss: 0.05748094990849495\n",
      "Epoch 8300/100000, Loss: 0.05697300657629967\n",
      "Epoch 8400/100000, Loss: 0.056471552699804306\n",
      "Epoch 8500/100000, Loss: 0.055974721908569336\n",
      "Epoch 8600/100000, Loss: 0.055482782423496246\n",
      "Epoch 8700/100000, Loss: 0.054995063692331314\n",
      "Epoch 8800/100000, Loss: 0.05451120063662529\n",
      "Epoch 8900/100000, Loss: 0.05402982234954834\n",
      "Epoch 9000/100000, Loss: 0.05355000123381615\n",
      "Epoch 9100/100000, Loss: 0.05307161062955856\n",
      "Epoch 9200/100000, Loss: 0.05259467288851738\n",
      "Epoch 9300/100000, Loss: 0.052117347717285156\n",
      "Epoch 9400/100000, Loss: 0.05164311081171036\n",
      "Epoch 9500/100000, Loss: 0.05117053538560867\n",
      "Epoch 9600/100000, Loss: 0.05069933086633682\n",
      "Epoch 9700/100000, Loss: 0.05022964999079704\n",
      "Epoch 9800/100000, Loss: 0.04976178705692291\n",
      "Epoch 9900/100000, Loss: 0.04929720610380173\n",
      "Epoch 10000/100000, Loss: 0.048835597932338715\n",
      "Epoch 10100/100000, Loss: 0.04837826266884804\n",
      "Epoch 10200/100000, Loss: 0.047925859689712524\n",
      "Epoch 10300/100000, Loss: 0.047478917986154556\n",
      "Epoch 10400/100000, Loss: 0.04703858494758606\n",
      "Epoch 10500/100000, Loss: 0.04660574346780777\n",
      "Epoch 10600/100000, Loss: 0.04618096351623535\n",
      "Epoch 10700/100000, Loss: 0.045764464884996414\n",
      "Epoch 10800/100000, Loss: 0.045356810092926025\n",
      "Epoch 10900/100000, Loss: 0.04495808482170105\n",
      "Epoch 11000/100000, Loss: 0.044568974524736404\n",
      "Epoch 11100/100000, Loss: 0.04418942332267761\n",
      "Epoch 11200/100000, Loss: 0.04381943121552467\n",
      "Epoch 11300/100000, Loss: 0.0434589721262455\n",
      "Epoch 11400/100000, Loss: 0.04310792684555054\n",
      "Epoch 11500/100000, Loss: 0.042766280472278595\n",
      "Epoch 11600/100000, Loss: 0.042433224618434906\n",
      "Epoch 11700/100000, Loss: 0.042108502238988876\n",
      "Epoch 11800/100000, Loss: 0.04179222136735916\n",
      "Epoch 11900/100000, Loss: 0.04148326814174652\n",
      "Epoch 12000/100000, Loss: 0.04118194431066513\n",
      "Epoch 12100/100000, Loss: 0.04088735580444336\n",
      "Epoch 12200/100000, Loss: 0.04059899225831032\n",
      "Epoch 12300/100000, Loss: 0.040316544473171234\n",
      "Epoch 12400/100000, Loss: 0.040039632469415665\n",
      "Epoch 12500/100000, Loss: 0.039767537266016006\n",
      "Epoch 12600/100000, Loss: 0.03950021415948868\n",
      "Epoch 12700/100000, Loss: 0.03923670947551727\n",
      "Epoch 12800/100000, Loss: 0.038976602256298065\n",
      "Epoch 12900/100000, Loss: 0.03871988505125046\n",
      "Epoch 13000/100000, Loss: 0.03846586123108864\n",
      "Epoch 13100/100000, Loss: 0.03821396082639694\n",
      "Epoch 13200/100000, Loss: 0.03796391561627388\n",
      "Epoch 13300/100000, Loss: 0.037715524435043335\n",
      "Epoch 13400/100000, Loss: 0.03746770694851875\n",
      "Epoch 13500/100000, Loss: 0.03722074627876282\n",
      "Epoch 13600/100000, Loss: 0.03697429969906807\n",
      "Epoch 13700/100000, Loss: 0.03672733157873154\n",
      "Epoch 13800/100000, Loss: 0.03648007661104202\n",
      "Epoch 13900/100000, Loss: 0.03623223304748535\n",
      "Epoch 14000/100000, Loss: 0.03598294034600258\n",
      "Epoch 14100/100000, Loss: 0.03573249280452728\n",
      "Epoch 14200/100000, Loss: 0.03548058122396469\n",
      "Epoch 14300/100000, Loss: 0.03522675856947899\n",
      "Epoch 14400/100000, Loss: 0.03497113659977913\n",
      "Epoch 14500/100000, Loss: 0.03471355512738228\n",
      "Epoch 14600/100000, Loss: 0.034453462809324265\n",
      "Epoch 14700/100000, Loss: 0.03419137001037598\n",
      "Epoch 14800/100000, Loss: 0.03392723947763443\n",
      "Epoch 14900/100000, Loss: 0.033660661429166794\n",
      "Epoch 15000/100000, Loss: 0.03339181840419769\n",
      "Epoch 15100/100000, Loss: 0.03312062844634056\n",
      "Epoch 15200/100000, Loss: 0.03284766525030136\n",
      "Epoch 15300/100000, Loss: 0.032573152333498\n",
      "Epoch 15400/100000, Loss: 0.0322963185608387\n",
      "Epoch 15500/100000, Loss: 0.03201816603541374\n",
      "Epoch 15600/100000, Loss: 0.03173859417438507\n",
      "Epoch 15700/100000, Loss: 0.03145778179168701\n",
      "Epoch 15800/100000, Loss: 0.031176278367638588\n",
      "Epoch 15900/100000, Loss: 0.03089354746043682\n",
      "Epoch 16000/100000, Loss: 0.030610041692852974\n",
      "Epoch 16100/100000, Loss: 0.03032606467604637\n",
      "Epoch 16200/100000, Loss: 0.03004165180027485\n",
      "Epoch 16300/100000, Loss: 0.029756933450698853\n",
      "Epoch 16400/100000, Loss: 0.029472608119249344\n",
      "Epoch 16500/100000, Loss: 0.02918809838593006\n",
      "Epoch 16600/100000, Loss: 0.028904151171445847\n",
      "Epoch 16700/100000, Loss: 0.028620216995477676\n",
      "Epoch 16800/100000, Loss: 0.028337158262729645\n",
      "Epoch 16900/100000, Loss: 0.02805468998849392\n",
      "Epoch 17000/100000, Loss: 0.027773316949605942\n",
      "Epoch 17100/100000, Loss: 0.027492521330714226\n",
      "Epoch 17200/100000, Loss: 0.027213165536522865\n",
      "Epoch 17300/100000, Loss: 0.026934649795293808\n",
      "Epoch 17400/100000, Loss: 0.026657868176698685\n",
      "Epoch 17500/100000, Loss: 0.02638200856745243\n",
      "Epoch 17600/100000, Loss: 0.026107830926775932\n",
      "Epoch 17700/100000, Loss: 0.025835368782281876\n",
      "Epoch 17800/100000, Loss: 0.025564588606357574\n",
      "Epoch 17900/100000, Loss: 0.02529565431177616\n",
      "Epoch 18000/100000, Loss: 0.025028225034475327\n",
      "Epoch 18100/100000, Loss: 0.02476293407380581\n",
      "Epoch 18200/100000, Loss: 0.024499861523509026\n",
      "Epoch 18300/100000, Loss: 0.02423877827823162\n",
      "Epoch 18400/100000, Loss: 0.023979514837265015\n",
      "Epoch 18500/100000, Loss: 0.023722566664218903\n",
      "Epoch 18600/100000, Loss: 0.023468047380447388\n",
      "Epoch 18700/100000, Loss: 0.02321559377014637\n",
      "Epoch 18800/100000, Loss: 0.02296559326350689\n",
      "Epoch 18900/100000, Loss: 0.02271791361272335\n",
      "Epoch 19000/100000, Loss: 0.022472821176052094\n",
      "Epoch 19100/100000, Loss: 0.022229772061109543\n",
      "Epoch 19200/100000, Loss: 0.021989084780216217\n",
      "Epoch 19300/100000, Loss: 0.021750763058662415\n",
      "Epoch 19400/100000, Loss: 0.021514389663934708\n",
      "Epoch 19500/100000, Loss: 0.021279703825712204\n",
      "Epoch 19600/100000, Loss: 0.021046455949544907\n",
      "Epoch 19700/100000, Loss: 0.02081415057182312\n",
      "Epoch 19800/100000, Loss: 0.020582804456353188\n",
      "Epoch 19900/100000, Loss: 0.020352397114038467\n",
      "Epoch 20000/100000, Loss: 0.020122485235333443\n",
      "Epoch 20100/100000, Loss: 0.019892938435077667\n",
      "Epoch 20200/100000, Loss: 0.019663766026496887\n",
      "Epoch 20300/100000, Loss: 0.019434917718172073\n",
      "Epoch 20400/100000, Loss: 0.019206296652555466\n",
      "Epoch 20500/100000, Loss: 0.018977070227265358\n",
      "Epoch 20600/100000, Loss: 0.018748518079519272\n",
      "Epoch 20700/100000, Loss: 0.018519243225455284\n",
      "Epoch 20800/100000, Loss: 0.018289849162101746\n",
      "Epoch 20900/100000, Loss: 0.018060239031910896\n",
      "Epoch 21000/100000, Loss: 0.017830457538366318\n",
      "Epoch 21100/100000, Loss: 0.017600394785404205\n",
      "Epoch 21200/100000, Loss: 0.017370155081152916\n",
      "Epoch 21300/100000, Loss: 0.01713903248310089\n",
      "Epoch 21400/100000, Loss: 0.016908273100852966\n",
      "Epoch 21500/100000, Loss: 0.01667698659002781\n",
      "Epoch 21600/100000, Loss: 0.016445882618427277\n",
      "Epoch 21700/100000, Loss: 0.016214333474636078\n",
      "Epoch 21800/100000, Loss: 0.015983400866389275\n",
      "Epoch 21900/100000, Loss: 0.015752485021948814\n",
      "Epoch 22000/100000, Loss: 0.015521690249443054\n",
      "Epoch 22100/100000, Loss: 0.015291444957256317\n",
      "Epoch 22200/100000, Loss: 0.015061914920806885\n",
      "Epoch 22300/100000, Loss: 0.014833785593509674\n",
      "Epoch 22400/100000, Loss: 0.014606392942368984\n",
      "Epoch 22500/100000, Loss: 0.014380017295479774\n",
      "Epoch 22600/100000, Loss: 0.014155076816678047\n",
      "Epoch 22700/100000, Loss: 0.01393179502338171\n",
      "Epoch 22800/100000, Loss: 0.013710955157876015\n",
      "Epoch 22900/100000, Loss: 0.013491576537489891\n",
      "Epoch 23000/100000, Loss: 0.013274375349283218\n",
      "Epoch 23100/100000, Loss: 0.013060183264315128\n",
      "Epoch 23200/100000, Loss: 0.012847891077399254\n",
      "Epoch 23300/100000, Loss: 0.012638934887945652\n",
      "Epoch 23400/100000, Loss: 0.01243247278034687\n",
      "Epoch 23500/100000, Loss: 0.012229165993630886\n",
      "Epoch 23600/100000, Loss: 0.012029214762151241\n",
      "Epoch 23700/100000, Loss: 0.01183247845619917\n",
      "Epoch 23800/100000, Loss: 0.011639059521257877\n",
      "Epoch 23900/100000, Loss: 0.011449331417679787\n",
      "Epoch 24000/100000, Loss: 0.011262988671660423\n",
      "Epoch 24100/100000, Loss: 0.011080185882747173\n",
      "Epoch 24200/100000, Loss: 0.010901041328907013\n",
      "Epoch 24300/100000, Loss: 0.01072563137859106\n",
      "Epoch 24400/100000, Loss: 0.010553810745477676\n",
      "Epoch 24500/100000, Loss: 0.010385562665760517\n",
      "Epoch 24600/100000, Loss: 0.010221309959888458\n",
      "Epoch 24700/100000, Loss: 0.010060230270028114\n",
      "Epoch 24800/100000, Loss: 0.009903069585561752\n",
      "Epoch 24900/100000, Loss: 0.009749360382556915\n",
      "Epoch 25000/100000, Loss: 0.009599132463335991\n",
      "Epoch 25100/100000, Loss: 0.009452600963413715\n",
      "Epoch 25200/100000, Loss: 0.009309206157922745\n",
      "Epoch 25300/100000, Loss: 0.00916922278702259\n",
      "Epoch 25400/100000, Loss: 0.009032582864165306\n",
      "Epoch 25500/100000, Loss: 0.008899211883544922\n",
      "Epoch 25600/100000, Loss: 0.008768785744905472\n",
      "Epoch 25700/100000, Loss: 0.008641601540148258\n",
      "Epoch 25800/100000, Loss: 0.008517347276210785\n",
      "Epoch 25900/100000, Loss: 0.008396036922931671\n",
      "Epoch 26000/100000, Loss: 0.008277601562440395\n",
      "Epoch 26100/100000, Loss: 0.008161940611898899\n",
      "Epoch 26200/100000, Loss: 0.00804894883185625\n",
      "Epoch 26300/100000, Loss: 0.007938558235764503\n",
      "Epoch 26400/100000, Loss: 0.007830824702978134\n",
      "Epoch 26500/100000, Loss: 0.0077254874631762505\n",
      "Epoch 26600/100000, Loss: 0.007622606121003628\n",
      "Epoch 26700/100000, Loss: 0.007522046100348234\n",
      "Epoch 26800/100000, Loss: 0.007423778064548969\n",
      "Epoch 26900/100000, Loss: 0.007327706553041935\n",
      "Epoch 27000/100000, Loss: 0.007233834825456142\n",
      "Epoch 27100/100000, Loss: 0.007142093498259783\n",
      "Epoch 27200/100000, Loss: 0.0070522562600672245\n",
      "Epoch 27300/100000, Loss: 0.006964465603232384\n",
      "Epoch 27400/100000, Loss: 0.00687857810407877\n",
      "Epoch 27500/100000, Loss: 0.006794624961912632\n",
      "Epoch 27600/100000, Loss: 0.006712373346090317\n",
      "Epoch 27700/100000, Loss: 0.006631928030401468\n",
      "Epoch 27800/100000, Loss: 0.006553169805556536\n",
      "Epoch 27900/100000, Loss: 0.006476073991507292\n",
      "Epoch 28000/100000, Loss: 0.006400605663657188\n",
      "Epoch 28100/100000, Loss: 0.006326700560748577\n",
      "Epoch 28200/100000, Loss: 0.006254285108298063\n",
      "Epoch 28300/100000, Loss: 0.006183338817209005\n",
      "Epoch 28400/100000, Loss: 0.006113877985626459\n",
      "Epoch 28500/100000, Loss: 0.00604573218151927\n",
      "Epoch 28600/100000, Loss: 0.005978990346193314\n",
      "Epoch 28700/100000, Loss: 0.00591360405087471\n",
      "Epoch 28800/100000, Loss: 0.005849456414580345\n",
      "Epoch 28900/100000, Loss: 0.00578656792640686\n",
      "Epoch 29000/100000, Loss: 0.005724879913032055\n",
      "Epoch 29100/100000, Loss: 0.005664382129907608\n",
      "Epoch 29200/100000, Loss: 0.0056050606071949005\n",
      "Epoch 29300/100000, Loss: 0.005546859931200743\n",
      "Epoch 29400/100000, Loss: 0.005489708855748177\n",
      "Epoch 29500/100000, Loss: 0.005433639977127314\n",
      "Epoch 29600/100000, Loss: 0.00537861417979002\n",
      "Epoch 29700/100000, Loss: 0.00532458396628499\n",
      "Epoch 29800/100000, Loss: 0.005271569825708866\n",
      "Epoch 29900/100000, Loss: 0.0052194660529494286\n",
      "Epoch 30000/100000, Loss: 0.005168312229216099\n",
      "Epoch 30100/100000, Loss: 0.005118086934089661\n",
      "Epoch 30200/100000, Loss: 0.005068741273134947\n",
      "Epoch 30300/100000, Loss: 0.005020225886255503\n",
      "Epoch 30400/100000, Loss: 0.0049725784920156\n",
      "Epoch 30500/100000, Loss: 0.00492577301338315\n",
      "Epoch 30600/100000, Loss: 0.004879732616245747\n",
      "Epoch 30700/100000, Loss: 0.004834501072764397\n",
      "Epoch 30800/100000, Loss: 0.004790023900568485\n",
      "Epoch 30900/100000, Loss: 0.004746295046061277\n",
      "Epoch 31000/100000, Loss: 0.0047033061273396015\n",
      "Epoch 31100/100000, Loss: 0.004661021288484335\n",
      "Epoch 31200/100000, Loss: 0.004619418643414974\n",
      "Epoch 31300/100000, Loss: 0.004578521009534597\n",
      "Epoch 31400/100000, Loss: 0.00453825993463397\n",
      "Epoch 31500/100000, Loss: 0.004498639144003391\n",
      "Epoch 31600/100000, Loss: 0.004459668882191181\n",
      "Epoch 31700/100000, Loss: 0.004421328194439411\n",
      "Epoch 31800/100000, Loss: 0.00438358448445797\n",
      "Epoch 31900/100000, Loss: 0.004346426576375961\n",
      "Epoch 32000/100000, Loss: 0.004309832584112883\n",
      "Epoch 32100/100000, Loss: 0.004273827187716961\n",
      "Epoch 32200/100000, Loss: 0.004238354507833719\n",
      "Epoch 32300/100000, Loss: 0.004203430842608213\n",
      "Epoch 32400/100000, Loss: 0.004169047810137272\n",
      "Epoch 32500/100000, Loss: 0.004135167691856623\n",
      "Epoch 32600/100000, Loss: 0.0041018035262823105\n",
      "Epoch 32700/100000, Loss: 0.004068918526172638\n",
      "Epoch 32800/100000, Loss: 0.00403653783723712\n",
      "Epoch 32900/100000, Loss: 0.00400460883975029\n",
      "Epoch 33000/100000, Loss: 0.003973160870373249\n",
      "Epoch 33100/100000, Loss: 0.003942176699638367\n",
      "Epoch 33200/100000, Loss: 0.003911617677658796\n",
      "Epoch 33300/100000, Loss: 0.003881515935063362\n",
      "Epoch 33400/100000, Loss: 0.003851820481941104\n",
      "Epoch 33500/100000, Loss: 0.003822562750428915\n",
      "Epoch 33600/100000, Loss: 0.003793698502704501\n",
      "Epoch 33700/100000, Loss: 0.0037652449682354927\n",
      "Epoch 33800/100000, Loss: 0.0037371746730059385\n",
      "Epoch 33900/100000, Loss: 0.003709504846483469\n",
      "Epoch 34000/100000, Loss: 0.003682210808619857\n",
      "Epoch 34100/100000, Loss: 0.003655291860923171\n",
      "Epoch 34200/100000, Loss: 0.003628725418820977\n",
      "Epoch 34300/100000, Loss: 0.003602516371756792\n",
      "Epoch 34400/100000, Loss: 0.003576654940843582\n",
      "Epoch 34500/100000, Loss: 0.003551153466105461\n",
      "Epoch 34600/100000, Loss: 0.0035259828437119722\n",
      "Epoch 34700/100000, Loss: 0.0035011323634535074\n",
      "Epoch 34800/100000, Loss: 0.0034766036551445723\n",
      "Epoch 34900/100000, Loss: 0.003452407428994775\n",
      "Epoch 35000/100000, Loss: 0.0034285211004316807\n",
      "Epoch 35100/100000, Loss: 0.0034049239475280046\n",
      "Epoch 35200/100000, Loss: 0.0033816471695899963\n",
      "Epoch 35300/100000, Loss: 0.0033586532808840275\n",
      "Epoch 35400/100000, Loss: 0.0033359546214342117\n",
      "Epoch 35500/100000, Loss: 0.0033135414123535156\n",
      "Epoch 35600/100000, Loss: 0.0032913999166339636\n",
      "Epoch 35700/100000, Loss: 0.0032695394475013018\n",
      "Epoch 35800/100000, Loss: 0.003247946733608842\n",
      "Epoch 35900/100000, Loss: 0.00322661898098886\n",
      "Epoch 36000/100000, Loss: 0.00320554431527853\n",
      "Epoch 36100/100000, Loss: 0.003184736706316471\n",
      "Epoch 36200/100000, Loss: 0.0031641731038689613\n",
      "Epoch 36300/100000, Loss: 0.0031438504811376333\n",
      "Epoch 36400/100000, Loss: 0.0031237804796546698\n",
      "Epoch 36500/100000, Loss: 0.0031039337627589703\n",
      "Epoch 36600/100000, Loss: 0.0030843443237245083\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fryde\\Documents\\projects\\MLP-from-scratch\\encoder_decoder\\encoder_decoder.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Create and train the model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m MLP(\u001b[39m8\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model, losses \u001b[39m=\u001b[39m train(model, inputs, targets, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m100000\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\fryde\\Documents\\projects\\MLP-from-scratch\\encoder_decoder\\encoder_decoder.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W1sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W1sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W1sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W1sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\fryde\\miniconda3\\envs\\CuVi\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\fryde\\miniconda3\\envs\\CuVi\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the input and target tensors for the 8-3-8 task\n",
    "inputs = torch.eye(8)\n",
    "targets = inputs.clone()\n",
    "\n",
    "# Create and train the model\n",
    "model = MLP(8, 3, 8)\n",
    "model, losses = train(model, inputs, targets, num_epochs=10000, learning_rate=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'builtin_function_or_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fryde\\Documents\\projects\\MLP-from-scratch\\encoder_decoder\\encoder_decoder.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Plot the learning curve\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(losses)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fryde/Documents/projects/MLP-from-scratch/encoder_decoder/encoder_decoder.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fryde\\miniconda3\\envs\\CuVi\\Lib\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[0;32m   2813\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[0;32m   2814\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fryde\\miniconda3\\envs\\CuVi\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1690\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m-> 1690\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_line(line)\n\u001b[0;32m   1691\u001b[0m \u001b[39mif\u001b[39;00m scalex:\n\u001b[0;32m   1692\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request_autoscale_view(\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fryde\\miniconda3\\envs\\CuVi\\Lib\\site-packages\\matplotlib\\axes\\_base.py:2304\u001b[0m, in \u001b[0;36m_AxesBase.add_line\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   2301\u001b[0m \u001b[39mif\u001b[39;00m line\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2302\u001b[0m     line\u001b[39m.\u001b[39mset_clip_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch)\n\u001b[1;32m-> 2304\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_line_limits(line)\n\u001b[0;32m   2305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mget_label():\n\u001b[0;32m   2306\u001b[0m     line\u001b[39m.\u001b[39mset_label(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_child\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_children)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fryde\\miniconda3\\envs\\CuVi\\Lib\\site-packages\\matplotlib\\axes\\_base.py:2327\u001b[0m, in \u001b[0;36m_AxesBase._update_line_limits\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   2323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_line_limits\u001b[39m(\u001b[39mself\u001b[39m, line):\n\u001b[0;32m   2324\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2325\u001b[0m \u001b[39m    Figures out the data limit of the given line, updating self.dataLim.\u001b[39;00m\n\u001b[0;32m   2326\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2327\u001b[0m     path \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39;49mget_path()\n\u001b[0;32m   2328\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mvertices\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2329\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fryde\\miniconda3\\envs\\CuVi\\Lib\\site-packages\\matplotlib\\lines.py:1028\u001b[0m, in \u001b[0;36mLine2D.get_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidy \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidx:\n\u001b[1;32m-> 1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecache()\n\u001b[0;32m   1029\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path\n",
      "File \u001b[1;32mc:\\Users\\fryde\\miniconda3\\envs\\CuVi\\Lib\\site-packages\\matplotlib\\lines.py:664\u001b[0m, in \u001b[0;36mLine2D.recache\u001b[1;34m(self, always)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[39mif\u001b[39;00m always \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidy:\n\u001b[0;32m    663\u001b[0m     yconv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_yunits(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_yorig)\n\u001b[1;32m--> 664\u001b[0m     y \u001b[39m=\u001b[39m _to_unmasked_float_array(yconv)\u001b[39m.\u001b[39mravel()\n\u001b[0;32m    665\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y\n",
      "File \u001b[1;32mc:\\Users\\fryde\\miniconda3\\envs\\CuVi\\Lib\\site-packages\\matplotlib\\cbook\\__init__.py:1340\u001b[0m, in \u001b[0;36m_to_unmasked_float_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1338\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39masarray(x, \u001b[39mfloat\u001b[39m)\u001b[39m.\u001b[39mfilled(np\u001b[39m.\u001b[39mnan)\n\u001b[0;32m   1339\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1340\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(x, \u001b[39mfloat\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'builtin_function_or_method'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curve\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "Output: tensor([[1.5609e-01, 1.5290e-01, 1.6570e-01, 1.5807e-01, 6.8846e-02, 7.9733e-02,\n",
      "         1.6259e-01, 1.6186e-01],\n",
      "        [1.4566e-01, 1.6288e-01, 1.1775e-01, 1.4715e-01, 1.3435e-01, 5.5071e-02,\n",
      "         1.2889e-01, 1.9336e-01],\n",
      "        [1.5207e-01, 1.2445e-01, 2.3003e-01, 1.5198e-01, 2.5159e-02, 1.4478e-01,\n",
      "         2.0281e-01, 1.0176e-01],\n",
      "        [1.6878e-01, 1.6547e-01, 1.7698e-01, 1.7277e-01, 7.1966e-02, 7.2860e-02,\n",
      "         1.7097e-01, 1.8573e-01],\n",
      "        [3.6786e-02, 9.5276e-02, 5.7567e-03, 3.1776e-02, 8.6082e-01, 1.7725e-02,\n",
      "         1.5946e-02, 1.1469e-01],\n",
      "        [1.9521e-02, 1.0081e-02, 1.0031e-01, 1.4038e-02, 1.0164e-03, 8.6055e-01,\n",
      "         9.9935e-02, 8.4773e-04],\n",
      "        [1.4513e-01, 1.1741e-01, 2.2584e-01, 1.4400e-01, 2.3210e-02, 1.5641e-01,\n",
      "         1.9957e-01, 9.1049e-02],\n",
      "        [2.2613e-01, 2.7440e-01, 1.4053e-01, 2.4318e-01, 2.7321e-01, 2.2301e-02,\n",
      "         1.5016e-01, 4.5357e-01]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print the resulting input and output values\n",
    "print('Input:', inputs)\n",
    "print('Output:', model(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the states of the hidden neurons\n",
    "hidden_states = model.hidden(inputs).detach()\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(hidden_states[i].reshape(1, 3), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CuVi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
